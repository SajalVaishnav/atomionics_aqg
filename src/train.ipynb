{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.optimize import curve_fit\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_FLOAT_PRECISION_NUMPY = np.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 29)\n",
      "(32, 29)\n"
     ]
    }
   ],
   "source": [
    "chirp_direction = 'chirp_up'\n",
    "data_file_path = r'C:\\Users\\vaish\\dsvv_atomionics\\compiled_data\\compiled_' + f'{chirp_direction}.pkl'\n",
    "data_cols = [\n",
    "\t\t'master_run_number', 'chirp_rate', 'fraction',\n",
    "\t\t'CA+_mean', 'CA+_std_dev', 'CA+_percentile_0', 'CA+_percentile_10', 'CA+_percentile_20', \n",
    "\t\t'CA+_percentile_30', 'CA+_percentile_40', 'CA+_percentile_50', 'CA+_percentile_60', 'CA+_percentile_70', \n",
    "\t\t'CA+_percentile_80', 'CA+_percentile_90', 'CA+_percentile_100', 'CA-_mean', 'CA-_std_dev', 'CA-_percentile_0', \n",
    "\t\t'CA-_percentile_10', 'CA-_percentile_20', 'CA-_percentile_30', 'CA-_percentile_40', 'CA-_percentile_50', \n",
    "\t\t'CA-_percentile_60', 'CA-_percentile_70', 'CA-_percentile_80', 'CA-_percentile_90', 'CA-_percentile_100'\n",
    "\t]\n",
    "\n",
    "data = pd.DataFrame(pd.read_pickle(data_file_path), columns=data_cols, dtype=GLOBAL_FLOAT_PRECISION_NUMPY)\n",
    "data = data.astype({'master_run_number': 'int32'})\n",
    "\n",
    "# 80-20 train/test split\n",
    "train_data_df = data.sample(frac=0.8, random_state=0)\n",
    "test_data_df = data.drop(train_data_df.index)\n",
    "\n",
    "print(train_data_df.shape)\n",
    "# print(train_data_df.head())\n",
    "print(test_data_df.shape)\n",
    "# print(test_data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 7)\n"
     ]
    }
   ],
   "source": [
    "compiled_constants_csv_path = r'C:\\Users\\vaish\\dsvv_atomionics\\compiled_data\\compiled_constants.csv'\n",
    "compiled_constants_df = pd.read_csv(compiled_constants_csv_path)\n",
    "compiled_constants_dtypes = {\n",
    "\t'master_run': 'int32',\n",
    "\t'chirp_direction': 'str',\n",
    "\t'bigT': GLOBAL_FLOAT_PRECISION_NUMPY,\n",
    "\t'Keff': GLOBAL_FLOAT_PRECISION_NUMPY,\n",
    "\t'contrast': GLOBAL_FLOAT_PRECISION_NUMPY,\n",
    "\t'g0': GLOBAL_FLOAT_PRECISION_NUMPY,\n",
    "\t'fringe_offset': GLOBAL_FLOAT_PRECISION_NUMPY\n",
    "}\n",
    "compiled_constants_df = compiled_constants_df.astype(compiled_constants_dtypes)\n",
    "\n",
    "print(compiled_constants_df.shape)\n",
    "# print(compiled_constants_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sine(alpha, Keff, bigT, contrast, g0, fringe_offset):\n",
    "    phi = (Keff * g0 - 2 * torch.pi * alpha) * (bigT**2)\n",
    "    return (-contrast * torch.cos(phi) + fringe_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_fractions_from_outputs(outputs, data_df):\n",
    "\tpredicted_fractions = []\n",
    "\tfor index in range(outputs.shape[0]):\n",
    "\t\tdata_row = data_df.iloc[index]\n",
    "\t\tmaster_run = data_row['master_run_number']\n",
    "\t\tcompiled_constants_row = compiled_constants_df[(compiled_constants_df['master_run'] == master_run) & (compiled_constants_df['chirp_direction'] == chirp_direction)]\n",
    "\n",
    "\t\tKeff = compiled_constants_row['Keff'].item()\n",
    "\t\tbigT = compiled_constants_row['bigT'].item()\n",
    "\t\tcontrast = compiled_constants_row['contrast'].item()\n",
    "\t\tg0 = compiled_constants_row['g0'].item()\n",
    "\t\tfringe_offset = compiled_constants_row['fringe_offset'].item()\n",
    "\t\tcurrent_output = outputs[index]\n",
    "\n",
    "\t\tpredicted_fraction = sine(current_output, Keff, bigT, contrast, g0, fringe_offset)\n",
    "\t\tpredicted_fractions.append(predicted_fraction)\n",
    "\t\n",
    "\tpredicted_fractions_tensor = torch.stack(predicted_fractions, 0)\n",
    "\treturn predicted_fractions_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-3.0785e-07, -3.0772e-07, -3.0782e-07],\n",
       "          [-3.0783e-07, -3.0781e-07, -3.0771e-07]],\n",
       "\n",
       "         [[-3.0777e-07, -3.0774e-07, -3.0785e-07],\n",
       "          [-3.0772e-07, -3.0774e-07, -3.0781e-07]],\n",
       "\n",
       "         [[-3.0782e-07, -3.0780e-07, -3.0786e-07],\n",
       "          [-3.0783e-07, -3.0776e-07, -3.0779e-07]],\n",
       "\n",
       "         [[-3.0781e-07, -3.0777e-07, -3.0772e-07],\n",
       "          [-3.0783e-07, -3.0779e-07, -3.0775e-07]],\n",
       "\n",
       "         [[-3.0782e-07, -3.0777e-07, -3.0774e-07],\n",
       "          [-3.0783e-07, -3.0782e-07, -3.0776e-07]]],\n",
       "\n",
       "\n",
       "        [[[-3.0773e-07, -3.0773e-07, -3.0774e-07],\n",
       "          [-3.0772e-07, -3.0783e-07, -3.0783e-07]],\n",
       "\n",
       "         [[-3.0772e-07, -3.0786e-07, -3.0784e-07],\n",
       "          [-3.0787e-07, -3.0778e-07, -3.0771e-07]],\n",
       "\n",
       "         [[-3.0781e-07, -3.0786e-07, -3.0787e-07],\n",
       "          [-3.0783e-07, -3.0771e-07, -3.0781e-07]],\n",
       "\n",
       "         [[-3.0783e-07, -3.0785e-07, -3.0780e-07],\n",
       "          [-3.0770e-07, -3.0780e-07, -3.0776e-07]],\n",
       "\n",
       "         [[-3.0777e-07, -3.0781e-07, -3.0786e-07],\n",
       "          [-3.0773e-07, -3.0783e-07, -3.0784e-07]]],\n",
       "\n",
       "\n",
       "        [[[-3.8310e-07, -3.8308e-07, -3.8309e-07],\n",
       "          [-3.8307e-07, -3.8319e-07, -3.8313e-07]],\n",
       "\n",
       "         [[-3.8319e-07, -3.8305e-07, -3.8318e-07],\n",
       "          [-3.8310e-07, -3.8313e-07, -3.8303e-07]],\n",
       "\n",
       "         [[-3.8311e-07, -3.8316e-07, -3.8315e-07],\n",
       "          [-3.8319e-07, -3.8306e-07, -3.8306e-07]],\n",
       "\n",
       "         [[-3.8311e-07, -3.8311e-07, -3.8309e-07],\n",
       "          [-3.8318e-07, -3.8311e-07, -3.8312e-07]],\n",
       "\n",
       "         [[-3.8311e-07, -3.8319e-07, -3.8319e-07],\n",
       "          [-3.8316e-07, -3.8315e-07, -3.8311e-07]]],\n",
       "\n",
       "\n",
       "        [[[-3.8311e-07, -3.8314e-07, -3.8310e-07],\n",
       "          [-3.8304e-07, -3.8317e-07, -3.8311e-07]],\n",
       "\n",
       "         [[-3.8303e-07, -3.8311e-07, -3.8319e-07],\n",
       "          [-3.8313e-07, -3.8307e-07, -3.8305e-07]],\n",
       "\n",
       "         [[-3.8319e-07, -3.8318e-07, -3.8315e-07],\n",
       "          [-3.8315e-07, -3.8314e-07, -3.8315e-07]],\n",
       "\n",
       "         [[-3.8310e-07, -3.8319e-07, -3.8309e-07],\n",
       "          [-3.8307e-07, -3.8319e-07, -3.8320e-07]],\n",
       "\n",
       "         [[-3.8311e-07, -3.8304e-07, -3.8316e-07],\n",
       "          [-3.8315e-07, -3.8316e-07, -3.8304e-07]]]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A little test you can run, to verify that gradients do propagate through this transformation\n",
    "# https://stackoverflow.com/questions/70426391/how-to-transform-output-of-nn-while-still-being-able-to-train\n",
    "\n",
    "# start with some random tensor representing the input predictions\n",
    "# make sure it requires_grad\n",
    "pred = torch.rand((4, 5, 2, 3)).requires_grad_(True)\n",
    "# transform it\n",
    "tpred = get_predicted_fractions_from_outputs(pred, train_data_df)\n",
    "\n",
    "# make up some \"default\" loss function and back-prop\n",
    "tpred.mean().backward()\n",
    "\n",
    "# check to see all gradients of the original prediction:\n",
    "pred.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark MSE score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_chirp_rates = torch.tensor(test_data_df['chirp_rate'].values)\n",
    "test_fractions = torch.tensor(test_data_df['fraction'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline MSE: 0.006329568853331391\n"
     ]
    }
   ],
   "source": [
    "predicted_fractions_tensor = get_predicted_fractions_from_outputs(test_chirp_rates, test_data_df)\n",
    "residuals_baseline = test_fractions - predicted_fractions_tensor\n",
    "mse_baseline = torch.mean(residuals_baseline ** 2)\n",
    "print(f'baseline MSE: {mse_baseline}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformationNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(TransformationNN, self).__init__()\n",
    "        # Define the layers of the network: 2 fully connected layers 27 -> 14 -> 7 -> 1\n",
    "        self.fc1 = nn.Linear(input_dim, 14)\n",
    "        self.fc2 = nn.Linear(14, 7)\n",
    "        self.fc3 = nn.Linear(7, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_tensor = torch.tensor(train_data_df.drop(columns=['fraction', 'master_run_number']).values)\n",
    "observed_fractions_tensor = torch.tensor(train_data_df['fraction'].values).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], MSE: 0.01598096918493165\n",
      "Epoch [101/1000], MSE: 0.010545176267308099\n",
      "Epoch [201/1000], MSE: 0.008056009626132128\n",
      "Epoch [301/1000], MSE: 0.007425348818370654\n",
      "Epoch [401/1000], MSE: 0.007300608618621926\n",
      "Epoch [501/1000], MSE: 0.007279224568808775\n",
      "Epoch [601/1000], MSE: 0.00727613553982301\n",
      "Epoch [701/1000], MSE: 0.007275778020363267\n",
      "Epoch [801/1000], MSE: 0.007275746144737557\n",
      "Epoch [901/1000], MSE: 0.007275744013178325\n"
     ]
    }
   ],
   "source": [
    "# Initialize the neural network\n",
    "model = TransformationNN(input_dim=27, output_dim=1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1)\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    outputs = model(training_data_tensor)\n",
    "    predicted_tensors = get_predicted_fractions_from_outputs(outputs, train_data_df)\n",
    "\n",
    "    loss = mse_loss_fn(predicted_tensors, observed_fractions_tensor)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % (num_epochs / 10) == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], MSE: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007288108624484816\n"
     ]
    }
   ],
   "source": [
    "test_chirp_rates_with_noise_tensor = torch.tensor(test_data_df.drop(columns=['fraction', 'master_run_number']).values, dtype=torch.float64)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Forward pass through the model\n",
    "with torch.no_grad():\n",
    "    corrected_chirp_rates = model(test_chirp_rates_with_noise_tensor)\n",
    "    predicted_fractions = get_predicted_fractions_from_outputs(corrected_chirp_rates, test_data_df)\n",
    "\n",
    "test_fractions_shape_corrected = test_fractions.view(-1, 1)\n",
    "\n",
    "# Calculate residuals and MSE\n",
    "residuals = predicted_fractions - test_fractions_shape_corrected\n",
    "mse = torch.mean(residuals ** 2)\n",
    "print(f'eval MSE: {mse.item()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
