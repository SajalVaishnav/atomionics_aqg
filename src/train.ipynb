{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_FLOAT_PRECISION_NUMPY = np.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 29)\n",
      "(32, 29)\n"
     ]
    }
   ],
   "source": [
    "chirp_direction = 'chirp_up'\n",
    "data_file_path = r'C:\\Users\\vaish\\dsvv_atomionics\\compiled_data\\compiled_' + f'{chirp_direction}.pkl'\n",
    "data_cols = [\n",
    "\t\t'master_run_number', 'chirp_rate', 'fraction',\n",
    "\t\t'CA+_mean', 'CA+_std_dev', 'CA+_percentile_0', 'CA+_percentile_10', 'CA+_percentile_20', \n",
    "\t\t'CA+_percentile_30', 'CA+_percentile_40', 'CA+_percentile_50', 'CA+_percentile_60', 'CA+_percentile_70', \n",
    "\t\t'CA+_percentile_80', 'CA+_percentile_90', 'CA+_percentile_100', 'CA-_mean', 'CA-_std_dev', 'CA-_percentile_0', \n",
    "\t\t'CA-_percentile_10', 'CA-_percentile_20', 'CA-_percentile_30', 'CA-_percentile_40', 'CA-_percentile_50', \n",
    "\t\t'CA-_percentile_60', 'CA-_percentile_70', 'CA-_percentile_80', 'CA-_percentile_90', 'CA-_percentile_100'\n",
    "\t]\n",
    "\n",
    "data = pd.DataFrame(pd.read_pickle(data_file_path), columns=data_cols, dtype=GLOBAL_FLOAT_PRECISION_NUMPY)\n",
    "data = data.astype({'master_run_number': 'int32'})\n",
    "\n",
    "# 80-20 train/test split\n",
    "train_data_df = data.sample(frac=0.8, random_state=0)\n",
    "test_data_df = data.drop(train_data_df.index)\n",
    "\n",
    "print(train_data_df.shape)\n",
    "# print(train_data_df.head())\n",
    "print(test_data_df.shape)\n",
    "# print(test_data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 7)\n"
     ]
    }
   ],
   "source": [
    "compiled_constants_csv_path = r'C:\\Users\\vaish\\dsvv_atomionics\\compiled_data\\compiled_constants.csv'\n",
    "compiled_constants_df = pd.read_csv(compiled_constants_csv_path)\n",
    "compiled_constants_dtypes = {\n",
    "\t'master_run': 'int32',\n",
    "\t'chirp_direction': 'str',\n",
    "\t'bigT': GLOBAL_FLOAT_PRECISION_NUMPY,\n",
    "\t'Keff': GLOBAL_FLOAT_PRECISION_NUMPY,\n",
    "\t'contrast': GLOBAL_FLOAT_PRECISION_NUMPY,\n",
    "\t'g0': GLOBAL_FLOAT_PRECISION_NUMPY,\n",
    "\t'fringe_offset': GLOBAL_FLOAT_PRECISION_NUMPY\n",
    "}\n",
    "compiled_constants_df = compiled_constants_df.astype(compiled_constants_dtypes)\n",
    "\n",
    "print(compiled_constants_df.shape)\n",
    "# print(compiled_constants_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting chirp rates to fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sine(alpha, Keff, bigT, contrast, g0, fringe_offset):\n",
    "    phi = (Keff * g0 - 2 * torch.pi * alpha) * (bigT**2)\n",
    "    return (-contrast * torch.cos(phi) + fringe_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_fractions_from_outputs(outputs, data_df):\n",
    "\tpredicted_fractions = []\n",
    "\tfor index in range(outputs.shape[0]):\n",
    "\t\tdata_row = data_df.iloc[index]\n",
    "\t\tmaster_run = data_row['master_run_number']\n",
    "\t\tcompiled_constants_row = compiled_constants_df[(compiled_constants_df['master_run'] == master_run) & (compiled_constants_df['chirp_direction'] == chirp_direction)]\n",
    "\n",
    "\t\tKeff = compiled_constants_row['Keff'].item()\n",
    "\t\tbigT = compiled_constants_row['bigT'].item()\n",
    "\t\tcontrast = compiled_constants_row['contrast'].item()\n",
    "\t\tg0 = compiled_constants_row['g0'].item()\n",
    "\t\tfringe_offset = compiled_constants_row['fringe_offset'].item()\n",
    "\t\tcurrent_output = outputs[index]\n",
    "\n",
    "\t\tpredicted_fraction = sine(current_output, Keff, bigT, contrast, g0, fringe_offset)\n",
    "\t\tpredicted_fractions.append(predicted_fraction)\n",
    "\t\n",
    "\tpredicted_fractions_tensor = torch.stack(predicted_fractions, 0)\n",
    "\treturn predicted_fractions_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-3.0780e-07, -3.0785e-07, -3.0781e-07],\n",
       "          [-3.0772e-07, -3.0776e-07, -3.0786e-07]],\n",
       "\n",
       "         [[-3.0782e-07, -3.0778e-07, -3.0775e-07],\n",
       "          [-3.0786e-07, -3.0773e-07, -3.0781e-07]],\n",
       "\n",
       "         [[-3.0782e-07, -3.0786e-07, -3.0772e-07],\n",
       "          [-3.0774e-07, -3.0775e-07, -3.0771e-07]],\n",
       "\n",
       "         [[-3.0770e-07, -3.0775e-07, -3.0778e-07],\n",
       "          [-3.0779e-07, -3.0785e-07, -3.0779e-07]],\n",
       "\n",
       "         [[-3.0776e-07, -3.0778e-07, -3.0786e-07],\n",
       "          [-3.0774e-07, -3.0781e-07, -3.0772e-07]]],\n",
       "\n",
       "\n",
       "        [[[-3.0777e-07, -3.0776e-07, -3.0779e-07],\n",
       "          [-3.0771e-07, -3.0786e-07, -3.0778e-07]],\n",
       "\n",
       "         [[-3.0774e-07, -3.0775e-07, -3.0779e-07],\n",
       "          [-3.0774e-07, -3.0786e-07, -3.0783e-07]],\n",
       "\n",
       "         [[-3.0771e-07, -3.0784e-07, -3.0784e-07],\n",
       "          [-3.0781e-07, -3.0780e-07, -3.0779e-07]],\n",
       "\n",
       "         [[-3.0774e-07, -3.0777e-07, -3.0775e-07],\n",
       "          [-3.0785e-07, -3.0775e-07, -3.0778e-07]],\n",
       "\n",
       "         [[-3.0777e-07, -3.0779e-07, -3.0781e-07],\n",
       "          [-3.0770e-07, -3.0786e-07, -3.0772e-07]]],\n",
       "\n",
       "\n",
       "        [[[-3.8314e-07, -3.8318e-07, -3.8318e-07],\n",
       "          [-3.8304e-07, -3.8317e-07, -3.8307e-07]],\n",
       "\n",
       "         [[-3.8304e-07, -3.8310e-07, -3.8311e-07],\n",
       "          [-3.8303e-07, -3.8311e-07, -3.8304e-07]],\n",
       "\n",
       "         [[-3.8306e-07, -3.8308e-07, -3.8308e-07],\n",
       "          [-3.8311e-07, -3.8309e-07, -3.8304e-07]],\n",
       "\n",
       "         [[-3.8305e-07, -3.8316e-07, -3.8316e-07],\n",
       "          [-3.8306e-07, -3.8305e-07, -3.8311e-07]],\n",
       "\n",
       "         [[-3.8309e-07, -3.8320e-07, -3.8305e-07],\n",
       "          [-3.8317e-07, -3.8310e-07, -3.8304e-07]]],\n",
       "\n",
       "\n",
       "        [[[-3.8307e-07, -3.8318e-07, -3.8309e-07],\n",
       "          [-3.8312e-07, -3.8311e-07, -3.8310e-07]],\n",
       "\n",
       "         [[-3.8312e-07, -3.8318e-07, -3.8310e-07],\n",
       "          [-3.8304e-07, -3.8310e-07, -3.8313e-07]],\n",
       "\n",
       "         [[-3.8305e-07, -3.8315e-07, -3.8313e-07],\n",
       "          [-3.8314e-07, -3.8317e-07, -3.8310e-07]],\n",
       "\n",
       "         [[-3.8309e-07, -3.8303e-07, -3.8319e-07],\n",
       "          [-3.8313e-07, -3.8317e-07, -3.8317e-07]],\n",
       "\n",
       "         [[-3.8310e-07, -3.8311e-07, -3.8315e-07],\n",
       "          [-3.8305e-07, -3.8306e-07, -3.8305e-07]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A little test you can run, to verify that gradients do propagate through this transformation\n",
    "# https://stackoverflow.com/questions/70426391/how-to-transform-output-of-nn-while-still-being-able-to-train\n",
    "\n",
    "# start with some random tensor representing the input predictions\n",
    "# make sure it requires_grad\n",
    "pred = torch.rand((4, 5, 2, 3)).requires_grad_(True)\n",
    "# transform it\n",
    "tpred = get_predicted_fractions_from_outputs(pred, train_data_df)\n",
    "\n",
    "# make up some \"default\" loss function and back-prop\n",
    "tpred.mean().backward()\n",
    "\n",
    "# check to see all gradients of the original prediction:\n",
    "pred.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSLE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSLELoss(pred, target):\n",
    "    return torch.mean((torch.log1p(pred) - torch.log1p(target)) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark MSE score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_chirp_rates = torch.tensor(test_data_df['chirp_rate'].values)\n",
    "test_fractions = torch.tensor(test_data_df['fraction'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_score(predicted_tensor, target_tensor, loss_fn):\n",
    "\tloss = loss_fn(predicted_tensor, target_tensor)\n",
    "\treturn loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE baseline score: 0.006329568853331391\n",
      "MSLE baseline score: 0.002648836092938011\n"
     ]
    }
   ],
   "source": [
    "predicted_fractions_tensor = get_predicted_fractions_from_outputs(test_chirp_rates, test_data_df)\n",
    "\n",
    "MSELoss = nn.MSELoss()\n",
    "mse_baseline_score = get_baseline_score(predicted_fractions_tensor, test_fractions, MSELoss)\n",
    "print(f'MSE baseline score: {mse_baseline_score}')\n",
    "\n",
    "msle_baseline_score = get_baseline_score(predicted_fractions_tensor, test_fractions, MSLELoss)\n",
    "print(f'MSLE baseline score: {msle_baseline_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformationNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(TransformationNN, self).__init__()\n",
    "        # Define the layers of the network: 2 fully connected layers 27 -> 14 -> 7 -> 1\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_tensor = torch.tensor(train_data_df.drop(columns=['fraction', 'master_run_number']).values)\n",
    "observed_fractions_tensor = torch.tensor(train_data_df['fraction'].values).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformationNN(input_dim=27, output_dim=1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "MSELoss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, epochs, training_data_tensor, observed_fractions_tensor):\n",
    "\tloss_values = []\n",
    "\tfor epoch in range(epochs):\n",
    "\t\tmodel.train()\n",
    "\n",
    "\t\t# Forward pass: Compute predicted y by passing x to the model\n",
    "\t\toutputs = model(training_data_tensor)\n",
    "\t\tpredicted_tensors = get_predicted_fractions_from_outputs(outputs, train_data_df)\n",
    "\n",
    "\t\tloss = loss_fn(predicted_tensors, observed_fractions_tensor)\n",
    "\t\tloss_values.append(loss.item())\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\tif epoch % (epochs / 10) == 0:\n",
    "\t\t\tprint(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item()}')\n",
    "\t\n",
    "\tplt.figure(figsize=(10, 6))\n",
    "\tplt.plot(range(epochs), loss_values, label='Training Loss')\n",
    "\tplt.xlabel('Epochs')\n",
    "\tplt.ylabel('Loss')\n",
    "\tplt.title('Training Loss vs. Epochs')\n",
    "\tplt.legend()\n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 0.01597793400946705\n",
      "Epoch [101/1000], Loss: 0.015448606962278644\n",
      "Epoch [201/1000], Loss: 0.014943221666267778\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMSELoss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_data_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobserved_fractions_tensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, loss_fn, epochs, training_data_tensor, observed_fractions_tensor)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Forward pass: Compute predicted y by passing x to the model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(training_data_tensor)\n\u001b[1;32m----> 8\u001b[0m predicted_tensors \u001b[38;5;241m=\u001b[39m \u001b[43mget_predicted_fractions_from_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(predicted_tensors, observed_fractions_tensor)\n\u001b[0;32m     11\u001b[0m loss_values\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m, in \u001b[0;36mget_predicted_fractions_from_outputs\u001b[1;34m(outputs, data_df)\u001b[0m\n\u001b[0;32m     12\u001b[0m \tfringe_offset \u001b[38;5;241m=\u001b[39m compiled_constants_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfringe_offset\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     13\u001b[0m \tcurrent_output \u001b[38;5;241m=\u001b[39m outputs[index]\n\u001b[1;32m---> 15\u001b[0m \tpredicted_fraction \u001b[38;5;241m=\u001b[39m \u001b[43msine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKeff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbigT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfringe_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \tpredicted_fractions\u001b[38;5;241m.\u001b[39mappend(predicted_fraction)\n\u001b[0;32m     18\u001b[0m predicted_fractions_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(predicted_fractions, \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m, in \u001b[0;36msine\u001b[1;34m(alpha, Keff, bigT, contrast, g0, fringe_offset)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msine\u001b[39m(alpha, Keff, bigT, contrast, g0, fringe_offset):\n\u001b[1;32m----> 2\u001b[0m     phi \u001b[38;5;241m=\u001b[39m (Keff \u001b[38;5;241m*\u001b[39m g0 \u001b[38;5;241m-\u001b[39m \u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m) \u001b[38;5;241m*\u001b[39m (bigT\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m-\u001b[39mcontrast \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mcos(phi) \u001b[38;5;241m+\u001b[39m fringe_offset)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, optimizer, MSELoss, 1000, training_data_tensor, observed_fractions_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_score(predicted_tensor, target_tensor, loss_fn):\n",
    "\tloss = loss_fn(predicted_tensor, target_tensor)\n",
    "\treturn loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE model score: 0.0072881096073342515\n",
      "MSLE model score: 0.0030700739889508383\n"
     ]
    }
   ],
   "source": [
    "test_chirp_rates_with_noise_tensor = torch.tensor(test_data_df.drop(columns=['fraction', 'master_run_number']).values, dtype=torch.float64)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Forward pass through the model\n",
    "with torch.no_grad():\n",
    "    corrected_chirp_rates = model(test_chirp_rates_with_noise_tensor)\n",
    "    predicted_fractions = get_predicted_fractions_from_outputs(corrected_chirp_rates, test_data_df)\n",
    "\n",
    "test_fractions_shape_corrected = test_fractions.view(-1, 1)\n",
    "mse_model_score = get_model_score(predicted_fractions, test_fractions_shape_corrected, MSELoss)\n",
    "print(f'MSE model score: {mse_model_score}')\n",
    "\n",
    "msle_model_score = get_model_score(predicted_fractions, test_fractions_shape_corrected, MSLELoss)\n",
    "print(f'MSLE model score: {msle_model_score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
